{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing the needed Modules/ Libraries"
      ],
      "metadata": {
        "id": "RJFplI6we40N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sTRBt0HMbuvS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "import string\n",
        "import spacy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the Dataset & the NLP model"
      ],
      "metadata": {
        "id": "F9X0qsuue_L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"toxic_comments.csv\")\n",
        "data = data.iloc[0:1000, :]\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stop_words = nlp.Defaults.stop_words\n",
        "punctuations = string.punctuation"
      ],
      "metadata": {
        "id": "5uDKUZ46fFXZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing ratio of toxic vs non-toxic comments\n",
        "sns.countplot(x='toxic', data=data, palette='Set1')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "sucUZlg9wUEf",
        "outputId": "ce76be0e-59b4-4f62-8f3b-d6bbd830fdf4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating our tokenizer to remove uneccessary words and characters."
      ],
      "metadata": {
        "id": "Erc4q0-Zn7Sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(sentence):\n",
        "  doc = nlp(sentence)\n",
        "  tokens = [word.lemma_.lower().strip() for word in doc]\n",
        "  tokens = [word for word in tokens if word not in stop_words and word not in punctuations]\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "ct2oqptHmm8O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizing our text data into numbers for NLP"
      ],
      "metadata": {
        "id": "rVq1p7VCo4qB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vector = CountVectorizer(tokenizer=tokenizer)\n",
        "tfidf_vector = TfidfVectorizer(tokenizer=tokenizer)\n",
        "# test to understand Tokenization & Vectorization\n",
        "test_example = count_vector.fit_transform([\"I loved chicken and rice. but to adjucate the lamb is to characterize the wolf. also chicken\", \n",
        "                            \"The chicken and the lamb were good.\"]).toarray()\n",
        "print(f'Sentence 1 tokenized: {tokenizer(\"I loved chicken and rice. but to adjucate the lamb is to characterize the wolf. also chicken\")}')\n",
        "print(f'Sentence 2 tokenized: {tokenizer(\"The chicken and the lamb were good.\")}')\n",
        "print(f'List of all features: {count_vector.get_feature_names_out()}')\n",
        "print(f'Frequency of each word: {count_vector.vocabulary_}')\n",
        "print(f'Vectorized Output: {test_example}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vaZ7-lBpEHT",
        "outputId": "e894d9d0-0419-4ef9-c623-59fbf2721632"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1 tokenized: ['love', 'chicken', 'rice', 'adjucate', 'lamb', 'characterize', 'wolf', 'chicken']\n",
            "Sentence 2 tokenized: ['chicken', 'lamb', 'good']\n",
            "List of all features: ['adjucate' 'characterize' 'chicken' 'good' 'lamb' 'love' 'rice' 'wolf']\n",
            "Frequency of each word: {'love': 5, 'chicken': 2, 'rice': 6, 'adjucate': 0, 'lamb': 4, 'characterize': 1, 'wolf': 7, 'good': 3}\n",
            "Vectorized Output: [[1 1 2 0 1 1 1 1]\n",
            " [0 0 1 1 1 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Splitting our dataset into Training and Test"
      ],
      "metadata": {
        "id": "6pUgHJtOwwYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = data['text'], data['toxic']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "X_train_vectors = count_vector.fit_transform(X_train).toarray()\n",
        "X_test_vectors = count_vector.transform(X_test).toarray()\n",
        "\n",
        "X_train_vectors_tfid = tfidf_vector.fit_transform(X_train).toarray()\n",
        "X_test_vectors_tfid = tfidf_vector.transform(X_test).toarray()"
      ],
      "metadata": {
        "id": "e6RKo8egv9yG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression Method"
      ],
      "metadata": {
        "id": "eGni4e-QxQT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr, lr_tfid = LogisticRegression(), LogisticRegression()\n",
        "lr.fit(X_train_vectors, y_train)\n",
        "y_pred = lr.predict(X_test_vectors)\n",
        "print(f\"Accuracy is: {metrics.accuracy_score(y_pred, y_test)}\")\n",
        "\n",
        "lr_tfid.fit(X_train_vectors_tfid, y_train)\n",
        "y_pred_tfid = lr_tfid.predict(X_test_vectors_tfid)\n",
        "print(f\"Accuracy with TFID is: {metrics.accuracy_score(y_pred_tfid, y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCwqrIVGsAoB",
        "outputId": "22437e9f-d8af-4f89-b105-cc6aa4f049e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 0.925\n",
            "Accuracy with TFID is: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K- Nearest neighbors Classifier Method"
      ],
      "metadata": {
        "id": "V3wBD4lcz8Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn, knn_tfid = KNeighborsClassifier(), KNeighborsClassifier()\n",
        "knn.fit(X_train_vectors, y_train)\n",
        "y_pred = knn.predict(X_test_vectors)\n",
        "print(f\"Accuracy is: {metrics.accuracy_score(y_pred, y_test)}\")\n",
        "\n",
        "knn_tfid.fit(X_train_vectors_tfid, y_train)\n",
        "y_pred_tfid = knn_tfid.predict(X_test_vectors_tfid)\n",
        "print(f\"Accuracy with TFID is: {metrics.accuracy_score(y_pred_tfid, y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXdQQYScz_sy",
        "outputId": "6d1f09d1-f098-44f4-e8d2-23ad340a63c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 0.905\n",
            "Accuracy with TFID is: 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gradient Booster Classifier Method"
      ],
      "metadata": {
        "id": "TYmVsPP805Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb, gb_tfid = GradientBoostingClassifier(random_state=0), GradientBoostingClassifier(random_state=0)\n",
        "gb.fit(X_train_vectors, y_train)\n",
        "y_pred = gb.predict(X_test_vectors)\n",
        "print(f\"Accuracy is: {metrics.accuracy_score(y_pred, y_test)}\")\n",
        "\n",
        "gb_tfid.fit(X_train_vectors_tfid, y_train)\n",
        "y_pred_tfid = gb_tfid.predict(X_test_vectors_tfid)\n",
        "print(f\"Accuracy with TFID is: {metrics.accuracy_score(y_pred_tfid, y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbVFoRFp07jm",
        "outputId": "b81aa058-05f3-4cb3-d3ec-2df4308a1d72"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 0.925\n",
            "Accuracy with TFID is: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest Classifier Method"
      ],
      "metadata": {
        "id": "voBEQhar9tWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf, rf_tfid = RandomForestClassifier(), RandomForestClassifier()\n",
        "rf.fit(X_train_vectors, y_train)\n",
        "y_pred = rf.predict(X_test_vectors)\n",
        "print(f\"Accuracy is: {metrics.accuracy_score(y_pred, y_test)}\")\n",
        "\n",
        "rf_tfid.fit(X_train_vectors_tfid, y_train)\n",
        "y_pred_tfid = rf_tfid.predict(X_test_vectors_tfid)\n",
        "print(f\"Accuracy with TFID is: {metrics.accuracy_score(y_pred_tfid, y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIgU4zWj9v6Q",
        "outputId": "beaf831d-0cb5-461d-d8d1-23ac30b13cb1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 0.92\n",
            "Accuracy with TFID is: 0.915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Naive Bayes Classifier Method"
      ],
      "metadata": {
        "id": "tlwp_KKL9yVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb, nb_tfid = GaussianNB(), GaussianNB()\n",
        "nb.fit(X_train_vectors, y_train)\n",
        "y_pred = nb.predict(X_test_vectors)\n",
        "print(f\"Accuracy is: {metrics.accuracy_score(y_pred, y_test)}\")\n",
        "\n",
        "nb_tfid.fit(X_train_vectors_tfid, y_train)\n",
        "y_pred_tfid = nb_tfid.predict(X_test_vectors_tfid)\n",
        "print(f\"Accuracy with TFID is: {metrics.accuracy_score(y_pred_tfid, y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6CroNNv-L0A",
        "outputId": "c627e4fa-ba3f-40e9-f598-7caffa8485dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 0.835\n",
            "Accuracy with TFID is: 0.835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Classifier Method"
      ],
      "metadata": {
        "id": "ZJVmZnwi_K-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt, dt_tfid = DecisionTreeClassifier(), DecisionTreeClassifier()\n",
        "dt.fit(X_train_vectors, y_train)\n",
        "y_pred = dt.predict(X_test_vectors)\n",
        "print(f\"Accuracy is: {metrics.accuracy_score(y_pred, y_test)}\")\n",
        "\n",
        "dt_tfid.fit(X_train_vectors_tfid, y_train)\n",
        "y_pred_tfid = dt_tfid.predict(X_test_vectors_tfid)\n",
        "print(f\"Accuracy with TFID is: {metrics.accuracy_score(y_pred_tfid, y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMDKbkiI_OjX",
        "outputId": "7e73e831-5e30-4b14-81cf-d4a2a062d9c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 0.9\n",
            "Accuracy with TFID is: 0.91\n"
          ]
        }
      ]
    }
  ]
}